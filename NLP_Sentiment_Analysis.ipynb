{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Patterns of Online Behavior\n",
    "#### 1. Surf/Browse - 1990 - 2000;\n",
    "#### 2. Search-Find-Obtain - 2000 - 2008;\n",
    "#### 3. Share-Discover - 2008 / Present -> Iphone launches(2008) -> users always online, share/discover through network, stream of online opinions;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opinions Contain Information\n",
    "#### * Reviews\n",
    "#### * Tweets and Posts\n",
    "#### * Messages\n",
    "#### * Swipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analyst - collect opinions, extract information from them and act on that information;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis System\n",
    "#### 1. Collect Opinions - Scrape/Harvest, comments, articles, tweets;\n",
    "\n",
    "#### 2. Extract Information - Sentiment Analysis; - Unconstructed data - need to tag the data - categorize the data into series;\n",
    "#### Analyse the categories of data; \n",
    "#### - Logistic Regression - Relationships between variables;\n",
    "#### - Quadrant analysis - Clusters of data with similar characteristics;\n",
    "\n",
    "#### 3. Act - Buy/sell stocks, target advertising spend, etc; - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications of Sentiment analysis\n",
    "\n",
    "#### 1. Event Driven Trading - Form of financial trading - traders need to react to news very quickly in form of company earning releases in contrast with analysist forecast before earnings are released.\n",
    "##### - company earning, versus forecast - only 2 outcomes - 1. Exceeded forecast; - 2. Missed Forecast; \n",
    "##### - simplistic way for an event-driven trader to know about his or her business - would be to buy the company's share if it exceeds the forecast and to sell the shares if it is below the forecast;\n",
    "##### - But the above approach is naive cause this information is priced into the market;\n",
    "##### - What the event driven trader really cares about is how the peak or the missed on forecast contrasts with the analyst sentiment before the forecast, this is where sentiment analysis becomes a valuable tool becomes vital;\n",
    "##### - Using sentiment analysis an event driven trader can tell too positive or too negative about a company;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###  Quadrant Matrix\n",
    "####                             Analyst Sentiment \n",
    "####                              Before Earning\n",
    "####                     ______________________________________\n",
    "####                     |(Buy)             |(Sell)            |\n",
    "####                     |(analyst -ve)     |(stock has        |\n",
    "####                     |(Forecast +ve)    |reached perfect)  |Exceeded\n",
    "####                     |                  |(A/F +ve)         | Forecast\n",
    "#### Company Earnings,   |__________________|__________________|\n",
    "#### versus Forecast     |(Buy)             |(sell)            |\n",
    "####                     |(Stock has        |(analyst +ve)     |Missed\n",
    "####                     |already plummeted)|(forecast -ve)    | Forecast\n",
    "####                     |                  |                  |\n",
    "####                     |__________________|__________________|\n",
    "####                       Negative       Positive       \n",
    "#### \n",
    "#### Insight: \"Buy the Rumor, Sell the News\";\n",
    "#### Buy the Rumor - If market sentiment was negative, buy even if earnings are poor;\n",
    "#### Sell the news - If market sentiment was positive, sell even if earnings are great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Customer satisfaction as measured in an online learning site.\n",
    "##### X-axis - Number of minutes watched;\n",
    "##### Y-axis - Viewer Comment on Online Course\n",
    "##### Result - inverse relationship: positive feedback -> lower # minutes watched; negative feedback -> higher # minutes watched;\n",
    "##### Insight: Fix the Finish - Strong start - The modules start well and make a strong first impression; Weak finish - The latter part of the course fails to hold viewer interest;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polarity Detection for Sentiment Analysis\n",
    "#### Some of the information embedded in opinions:\n",
    "#### 1.  Polarity - Positive or Negative?\n",
    "#### 2. Subjective - Subjective or Objective?\n",
    "#### 3. Aspects - Part or whole?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis as Binary Classification - Polarity (+ve / -ve)\n",
    "#### (Comment/Problem instance) -> | Binary Classifier | -> (+1 or -1 / assigned label);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification Problem\n",
    "#### i. Problem instance - The data item to be classified - usually unstructured text - email/text/etc;\n",
    "#### ii. Feature Vector: Word Tuple - Any representation of the attributes of the problem instance; or Word Frequency Set: A different representation - setting up the feature vector correctly; Stop Words Eliminated\n",
    "#### Category Set - the set with two values - need to find which value applies to the problem instance;\n",
    "#### Assigned  Label - Result - the category that the problem instance belongs to - as decided by the classifier. \n",
    "#### Corpus - A large number of data items, collectively available to the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based and Machine Learning Based Classifier:\n",
    "### Sentiment Analysis as Binary Classification\n",
    "#### Problem Instance -------> Binary Classifier -------> Assigned Label\n",
    "#### Binary Classifier 2 types:\n",
    "#### 1. Rule-based Classifier - Rules drwan up by experts are used to assign a label to problem instance.\n",
    "#### 2. ML-based Classifiers - Label is assigned based on patterns displayed in aggregate data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between Rule-based V/s ML-based\n",
    "\n",
    "### Rule-based:\n",
    "#### --------------------------------------\n",
    "#### 1. Static - rule are applied independent of data being analysed;\n",
    "#### 2. Experts need to formulate rules;\n",
    "#### 3. Can operate on isolated problem instances;\n",
    "#### 4. To update classifier, update rules;\n",
    "#### 5. No training step Required\n",
    "\n",
    "### ML-based\n",
    "#### ---------------------------------------\n",
    "#### 1. Dynamic - alter output based on patterns in data;\n",
    "#### 2. No need for expert skill;\n",
    "#### 3. Corpus of data needed, cannot operate on isolated problem instances;\n",
    "#### 4. To update classifier, update corpus;\n",
    "#### 5. Might require an explicit 'training' step (depends on the ML technique employed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Solving Sentiment Analysis with a Rule-based Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building is Hard, Using is Easy\n",
    "#### Builder - Building a sophisticated sentiment analysis system is hard; User - using a sophisticated sentiment analysis system is easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplistic Rule-based Approach to Polarity Detection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule-Based Binary Classifier\n",
    "#### Problem Instance -------> Rule-based Classifier -----------> Assigned Label\n",
    "#### Corppus/historical data ---> Human Exprets -----> Rule-based Classifier----> Assigned Labels;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Rule-based Classifier\n",
    "\n",
    "#### 1. Split text fragments into words; (Split documents into paragraphs; Split paragraphs into sentences; Split sentences into words; Simple library functions available;)\n",
    "\n",
    "#### 2. Calculate polarity of individual words; (Tag each word as positive or negative; Ignore nuetral words entirely; Require use of sentiment lexicon(datastructure,like a dictionary for polarity lookup) also provides intensity of its +ve/-ve ness);\n",
    "\n",
    "#### 3. Aggregate word polarities;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "#### \"This is the worst restaurant in the metropolis, by a long way\"\n",
    "#### Step 1: split text;\n",
    "#### Step 2: Map their polarities; (all words are nuetral except worst - negative);\n",
    "#### Step 3: Aggregate; -> negative;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitation of the Simplistic Rule-based Classifier:\n",
    "#### * Double negations fail -> \"This is not the worst restaurant in the metropolis, not by a long way\" -> +ve but algorithm will return it as +ve;\n",
    "#### * Contrasting adjective and contrasting conjunctions - fail;\n",
    "#### Service is satisfactory -> +ve; Service is barely satisfactory -> (although it is negative, it will be treated as +ve);\n",
    "#### * Punctuations gets ignored -> \"Is this the excellent ambiance the price would suggest?\" -> not very positive by the approach will return +ve;\n",
    "#### * Lacks to identify intensity; \"This is the worst day\"; \"This is the WORST day\" - both are treated same, although 2nd one is more negative;\n",
    "#### * Statements with both positive and negative words will bewilder the algorithm -> \"Service is amazing although the food is terrible\";\n",
    "\n",
    "### 1. Intensity -> Valency, Boosters, Punctuation, Capitalization;\n",
    "### 2. Reversal -> Negation, Contrasting, Conjunctions, and adverbs;\n",
    "### 3. Context -> Different Meanings in different context;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Realistic Rule-based Approach\n",
    "\n",
    "### 1. Intensity -> Valency, Boosters, Punctuation, Capitalization;\n",
    "### a. Use sentiment lexicon that includes valence scores;\n",
    "#### Good - +1.8; Great - +2.3; Fine - +2.0; Amazing - +2.9\n",
    "### b. Intensity modulated by boosters.\n",
    "#### \"really\", \"so\", \"such\", etc;\n",
    "### c. punctuation - !!!, ??\n",
    "#### \"This food is good!!!\" -> emphatic praise\n",
    "#### \"Chill-flavored icecream???\" -> subjective;\n",
    "### d. Capitalization\n",
    "#### \"This food is GOOD\" - emphasis must be noted;\n",
    "\n",
    "### 2. Reversal\n",
    "### a. Polarity is flipped by negation.\n",
    "#### \"This food is not good\"; \"This is not the worst restuarant in the metropolis\"\n",
    "### b. Polarity is subtly influenced by contrast;\n",
    "#### but, however, etc;\n",
    "\n",
    "### 3. Context\n",
    "#### - Difficult for Rule-based approaches;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sentiment Lexicons\n",
    "#### * Sentiment Lexicons contain word metadata;\n",
    "#### * Sentiment lexicons form the core of virtually all sentiment analysis systems (rule-based and ML-based);\n",
    "#### * Dictionary -> Lookup table for meanings of words;\n",
    "#### * Thesaurus -> Lookup table for synonyms for words;\n",
    "#### * Sentiment Lexicon -> Lookup table for intensity, polarity, ..;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reliable and Widely used Sentiment lexicons:\n",
    "#### 1. Sentiwordnet\n",
    "#### 2. MPQA - Multi-purpose question answering;(Subjective Data)\n",
    "#### 3. LIWC - Linquistic query and word count;\n",
    "#### 4. General Inquirer;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various Classes of information a sentiment lexicon can contain:\n",
    "#### 1. Polarity - Positive / Negative;\n",
    "#### 2. Subjective - Objective / Subjective;\n",
    "#### 3. Affective state - Emotions, Moods, Attitude, Personality trait, Interpersonal stance;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a sentiment analysis system is hard but using is easy:\n",
    "### VADER - Sophisticated rule-based system;\n",
    "### Sentiwordnet - A sophisticated sentiment lexicon;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Sentiment Analysis System with a rule-based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * VADER is is a RULE-based Binary Classifier\n",
    "#### Problem Instance ----> Rulebased Classifier (Human Experts) ------> Polarity Scores(Overall/ +ve/-ve/neutral);\n",
    "#### Valence Aware Dictionary for sEntiment Reasoning; (VADER)\n",
    "#### VADER is both algorithm and Dataset; Algorithm (Takes in text, calculates polarity and valence using rules); Dataset (Lexicon with valence scores for words, idioms, emoticons,etc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AMI_1234\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': -0.4767, 'neg': 0.608, 'neu': 0.392, 'pos': 0.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia = vader.SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(\"What a terrible restaurant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': -0.4767, 'neg': 1.0, 'neu': 0.0, 'pos': 0.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.5106, 'neg': 0.0, 'neu': 0.0, 'pos': 1.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\":D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': -0.34, 'neg': 1.0, 'neu': 0.0, 'pos': 0.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\":/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': -0.6124, 'neg': 0.5, 'neu': 0.5, 'pos': 0.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"the cumin was the kiss of death\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.4404, 'neg': 0.0, 'neu': 0.508, 'pos': 0.492}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"the food was good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.4926, 'neg': 0.0, 'neu': 0.484, 'pos': 0.516}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"the food was good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.5399, 'neg': 0.0, 'neu': 0.463, 'pos': 0.537}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"the food was good!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': -0.457, 'neg': 0.428, 'neu': 0.572, 'pos': 0.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"the food was not good!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.5964, 'neg': 0.0, 'neu': 0.563, 'pos': 0.437}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"the food was not the worst!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.5622, 'neg': 0.0, 'neu': 0.452, 'pos': 0.548}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"the food was GOOD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.4404, 'neg': 0.0, 'neu': 0.508, 'pos': 0.492}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"the food was good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.5777, 'neg': 0.0, 'neu': 0.517, 'pos': 0.483}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"the food was so good\") #booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.3291, 'neg': 0.234, 'neu': 0.398, 'pos': 0.368}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"I usually hate seafood but I liked this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': -0.2263, 'neg': 0.352, 'neu': 0.381, 'pos': 0.267}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"I usually hate seafood and I liked this\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing A rule-based approach using VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Download Corpus - 10000+ pre-classified movie reviews; (http://www.cs.cornell.edu/People/pabo/movie-review-data/)\n",
    "#### 2. Classifier with VADER - Positive or Negative? Use VADER's compound score to decide.\n",
    "#### 3. Measure Accuracy - Calculate percentage accuracy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Read in the Reviews\n",
    "positiveReviewsFileName = \"/Users/AMI_1234/Documents/Computer_programs/ML/python_ml/nlp_movie_review/rt-polaritydata/rt-polarity.pos\"\n",
    "\n",
    "with open(positiveReviewsFileName, 'r') as f:\n",
    "    positiveReviews = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positiveReviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positiveReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Read in the Reviews\n",
    "negativeReviewsFileName = \"/Users/AMI_1234/Documents/Computer_programs/ML/python_ml/nlp_movie_review/rt-polaritydata/rt-polarity.neg\"\n",
    "\n",
    "with open(negativeReviewsFileName, 'r') as f:\n",
    "    negativeReviews = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'simplistic , silly and tedious . \\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negativeReviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negativeReviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER on cornell's movie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import vader\n",
    "sia = vader.SentimentIntensityAnalyzer()\n",
    "def vaderSentiment(review):\n",
    "    return sia.polarity_scores(review)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6369"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"This is the best restaurant in the city\"\n",
    "vaderSentiment(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply VADER to the Reviews\n",
    "#### Python syntax for applying a function to each element of a list;\n",
    "\n",
    "#### Code Reuse with getReviewSentiments\n",
    "#### Input(Function Object) ---> Internal Working --------> Output(Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getReviewSentiments(sentimentCalculator):\n",
    "    negReviewResult = [sentimentCalculator(oneNegativeReview) for oneNegativeReview in negativeReviews]\n",
    "    posReviewResult = [sentimentCalculator(onePositiveReview) for onePositiveReview in positiveReviews]\n",
    "    return {'results-on-positive':posReviewResult, 'results-on-negative': negReviewResult}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3612,\n",
       " 0.8069,\n",
       " 0.2617,\n",
       " 0.8271,\n",
       " 0.6592,\n",
       " 0.5994,\n",
       " 0.4215,\n",
       " -0.5994,\n",
       " 0.0938,\n",
       " 0.4939,\n",
       " 0.4588,\n",
       " 0.6115,\n",
       " 0.0,\n",
       " 0.6369,\n",
       " 0.0,\n",
       " 0.2944,\n",
       " 0.0,\n",
       " 0.6249,\n",
       " 0.5859,\n",
       " 0.6249,\n",
       " 0.3818,\n",
       " 0.9058,\n",
       " -0.7506,\n",
       " 0.5719,\n",
       " 0.4588,\n",
       " 0.5256,\n",
       " 0.0,\n",
       " 0.8658,\n",
       " 0.8074,\n",
       " 0.8316,\n",
       " -0.1027,\n",
       " -0.1027,\n",
       " 0.4588,\n",
       " -0.0516,\n",
       " 0.6361,\n",
       " 0.4019,\n",
       " 0.6369,\n",
       " -0.2023,\n",
       " 0.8625,\n",
       " 0.3612,\n",
       " 0.6597,\n",
       " 0.5719,\n",
       " 0.8658,\n",
       " 0.0,\n",
       " 0.7906,\n",
       " 0.3612,\n",
       " 0.5859,\n",
       " 0.0,\n",
       " 0.4404,\n",
       " 0.7906,\n",
       " 0.34,\n",
       " 0.0,\n",
       " 0.8481,\n",
       " 0.3182,\n",
       " 0.6124,\n",
       " 0.5859,\n",
       " 0.3182,\n",
       " 0.631,\n",
       " 0.5859,\n",
       " 0.582,\n",
       " 0.5106,\n",
       " 0.296,\n",
       " 0.5106,\n",
       " 0.3612,\n",
       " -0.1779,\n",
       " 0.7845,\n",
       " -0.0231,\n",
       " 0.6249,\n",
       " 0.5994,\n",
       " -0.5434,\n",
       " 0.4588,\n",
       " -0.0516,\n",
       " 0.8957,\n",
       " 0.6249,\n",
       " 0.5267,\n",
       " 0.855,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.1027,\n",
       " -0.0489,\n",
       " 0.8555,\n",
       " 0.879,\n",
       " 0.296,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6361,\n",
       " -0.0258,\n",
       " 0.6369,\n",
       " 0.2732,\n",
       " 0.7506,\n",
       " 0.8885,\n",
       " 0.5574,\n",
       " 0.771,\n",
       " 0.5106,\n",
       " -0.1027,\n",
       " -0.25,\n",
       " -0.3291,\n",
       " -0.8442,\n",
       " 0.0,\n",
       " 0.6542,\n",
       " 0.8313,\n",
       " 0.0,\n",
       " 0.128,\n",
       " 0.25,\n",
       " 0.4404,\n",
       " 0.3182,\n",
       " 0.6369,\n",
       " 0.4767,\n",
       " 0.3182,\n",
       " 0.7351,\n",
       " 0.6369,\n",
       " 0.8271,\n",
       " 0.4588,\n",
       " -0.4019,\n",
       " 0.7184,\n",
       " 0.0,\n",
       " 0.3291,\n",
       " 0.5859,\n",
       " 0.4404,\n",
       " -0.3151,\n",
       " 0.743,\n",
       " 0.0,\n",
       " 0.7783,\n",
       " 0.9623,\n",
       " -0.25,\n",
       " 0.8957,\n",
       " 0.128,\n",
       " 0.3612,\n",
       " 0.2382,\n",
       " -0.0258,\n",
       " 0.4497,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0772,\n",
       " 0.4295,\n",
       " -0.0258,\n",
       " 0.5994,\n",
       " 0.5994,\n",
       " 0.4939,\n",
       " -0.3798,\n",
       " 0.3818,\n",
       " -0.4215,\n",
       " 0.2023,\n",
       " 0.9105,\n",
       " 0.6771,\n",
       " 0.6652,\n",
       " 0.6486,\n",
       " 0.8047,\n",
       " 0.9383,\n",
       " -0.6041,\n",
       " 0.0,\n",
       " 0.4215,\n",
       " 0.8885,\n",
       " 0.0,\n",
       " 0.8547,\n",
       " 0.6908,\n",
       " 0.7783,\n",
       " 0.8126,\n",
       " 0.4939,\n",
       " 0.7351,\n",
       " 0.3506,\n",
       " -0.6759,\n",
       " 0.0,\n",
       " 0.0258,\n",
       " 0.8201,\n",
       " 0.6808,\n",
       " 0.5859,\n",
       " -0.3036,\n",
       " -0.4404,\n",
       " 0.4588,\n",
       " 0.8527,\n",
       " 0.0,\n",
       " 0.8934,\n",
       " 0.6908,\n",
       " 0.6369,\n",
       " 0.296,\n",
       " 0.3612,\n",
       " 0.8397,\n",
       " 0.4927,\n",
       " 0.795,\n",
       " 0.4588,\n",
       " 0.5974,\n",
       " 0.4927,\n",
       " 0.7311,\n",
       " 0.3384,\n",
       " 0.6369,\n",
       " 0.8176,\n",
       " 0.4139,\n",
       " -0.3384,\n",
       " 0.5106,\n",
       " 0.8856,\n",
       " 0.7783,\n",
       " 0.8793,\n",
       " 0.4939,\n",
       " 0.5106,\n",
       " -0.0772,\n",
       " 0.0516,\n",
       " 0.6361,\n",
       " 0.9153,\n",
       " 0.6705,\n",
       " 0.1779,\n",
       " 0.5267,\n",
       " 0.7906,\n",
       " 0.7184,\n",
       " 0.5267,\n",
       " -0.7354,\n",
       " 0.128,\n",
       " 0.8201,\n",
       " 0.0,\n",
       " 0.7579,\n",
       " 0.7351,\n",
       " 0.5994,\n",
       " 0.7408,\n",
       " -0.0772,\n",
       " 0.4404,\n",
       " 0.0,\n",
       " 0.7102,\n",
       " 0.7506,\n",
       " 0.4404,\n",
       " 0.5423,\n",
       " 0.0516,\n",
       " -0.5719,\n",
       " 0.7184,\n",
       " 0.5859,\n",
       " 0.34,\n",
       " 0.5423,\n",
       " 0.7688,\n",
       " 0.9081,\n",
       " 0.8682,\n",
       " 0.6369,\n",
       " 0.7617,\n",
       " 0.3919,\n",
       " 0.4404,\n",
       " 0.0,\n",
       " 0.2023,\n",
       " 0.5106,\n",
       " 0.871,\n",
       " 0.0,\n",
       " 0.7783,\n",
       " 0.3274,\n",
       " 0.4443,\n",
       " 0.872,\n",
       " 0.1211,\n",
       " 0.9161,\n",
       " 0.6908,\n",
       " 0.6124,\n",
       " 0.0,\n",
       " 0.25,\n",
       " -0.4404,\n",
       " 0.5719,\n",
       " 0.7964,\n",
       " 0.8625,\n",
       " -0.8951,\n",
       " 0.4497,\n",
       " 0.5859,\n",
       " 0.7269,\n",
       " -0.6997,\n",
       " 0.0,\n",
       " 0.7717,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.4404,\n",
       " 0.5023,\n",
       " 0.4404,\n",
       " 0.4404,\n",
       " 0.5106,\n",
       " -0.4535,\n",
       " 0.6067,\n",
       " 0.5574,\n",
       " 0.1531,\n",
       " 0.4939,\n",
       " 0.9731,\n",
       " 0.4019,\n",
       " 0.4215,\n",
       " 0.0,\n",
       " 0.931,\n",
       " 0.0,\n",
       " 0.938,\n",
       " 0.7351,\n",
       " 0.2144,\n",
       " 0.8519,\n",
       " -0.4585,\n",
       " 0.7981,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1027,\n",
       " -0.7275,\n",
       " -0.4019,\n",
       " 0.4939,\n",
       " 0.0,\n",
       " 0.4404,\n",
       " 0.7506,\n",
       " -0.4019,\n",
       " 0.0,\n",
       " -0.7269,\n",
       " 0.5994,\n",
       " 0.7717,\n",
       " 0.8481,\n",
       " -0.605,\n",
       " 0.5859,\n",
       " 0.8519,\n",
       " 0.6472,\n",
       " -0.765,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.8225,\n",
       " 0.4767,\n",
       " 0.3818,\n",
       " 0.8519,\n",
       " -0.296,\n",
       " 0.1749,\n",
       " 0.7804,\n",
       " 0.4617,\n",
       " 0.4939,\n",
       " 0.743,\n",
       " 0.5719,\n",
       " 0.0,\n",
       " 0.0516,\n",
       " 0.5699,\n",
       " -0.5106,\n",
       " 0.0,\n",
       " 0.4588,\n",
       " 0.7351,\n",
       " 0.5574,\n",
       " 0.128,\n",
       " 0.4215,\n",
       " 0.7469,\n",
       " 0.4767,\n",
       " 0.7505,\n",
       " -0.4779,\n",
       " 0.1531,\n",
       " 0.1027,\n",
       " 0.0,\n",
       " 0.5859,\n",
       " 0.2023,\n",
       " 0.8555,\n",
       " 0.6705,\n",
       " 0.5859,\n",
       " 0.5777,\n",
       " 0.7906,\n",
       " -0.4404,\n",
       " -0.296,\n",
       " 0.4404,\n",
       " 0.8402,\n",
       " 0.6124,\n",
       " 0.5574,\n",
       " -0.2249,\n",
       " 0.807,\n",
       " 0.0,\n",
       " 0.4215,\n",
       " 0.4404,\n",
       " 0.7184,\n",
       " 0.5106,\n",
       " 0.9186,\n",
       " 0.0,\n",
       " 0.8979,\n",
       " 0.0,\n",
       " -0.296,\n",
       " 0.8555,\n",
       " 0.7964,\n",
       " 0.6597,\n",
       " -0.5574,\n",
       " 0.0572,\n",
       " 0.2617,\n",
       " 0.0258,\n",
       " -0.2411,\n",
       " 0.4019,\n",
       " 0.5719,\n",
       " 0.1336,\n",
       " 0.886,\n",
       " 0.0,\n",
       " 0.3818,\n",
       " 0.0,\n",
       " -0.6344,\n",
       " 0.6369,\n",
       " -0.25,\n",
       " 0.4939,\n",
       " 0.6705,\n",
       " 0.1263,\n",
       " 0.4588,\n",
       " -0.0018,\n",
       " 0.6665,\n",
       " 0.3818,\n",
       " -0.7506,\n",
       " 0.0,\n",
       " 0.802,\n",
       " -0.5279,\n",
       " 0.8807,\n",
       " 0.4404,\n",
       " 0.5924,\n",
       " -0.5707,\n",
       " 0.6597,\n",
       " 0.5719,\n",
       " 0.0,\n",
       " 0.8834,\n",
       " 0.4648,\n",
       " -0.5423,\n",
       " -0.8151,\n",
       " 0.891,\n",
       " 0.8868,\n",
       " 0.6259,\n",
       " 0.5859,\n",
       " -0.5423,\n",
       " 0.6808,\n",
       " 0.3919,\n",
       " 0.3612,\n",
       " 0.6705,\n",
       " 0.0,\n",
       " 0.7684,\n",
       " 0.6361,\n",
       " 0.7964,\n",
       " 0.4767,\n",
       " 0.4019,\n",
       " -0.1893,\n",
       " 0.5542,\n",
       " -0.1994,\n",
       " 0.7096,\n",
       " 0.8807,\n",
       " -0.0258,\n",
       " -0.4404,\n",
       " 0.7096,\n",
       " 0.0258,\n",
       " 0.9153,\n",
       " 0.0,\n",
       " -0.233,\n",
       " 0.0781,\n",
       " -0.34,\n",
       " 0.7351,\n",
       " 0.6597,\n",
       " -0.0332,\n",
       " 0.9153,\n",
       " 0.4033,\n",
       " 0.2992,\n",
       " -0.4902,\n",
       " -0.1027,\n",
       " 0.7845,\n",
       " 0.6705,\n",
       " 0.7964,\n",
       " 0.296,\n",
       " 0.3612,\n",
       " 0.7096,\n",
       " -0.25,\n",
       " 0.836,\n",
       " 0.6369,\n",
       " -0.8316,\n",
       " 0.7783,\n",
       " 0.3919,\n",
       " 0.6616,\n",
       " 0.7269,\n",
       " 0.5423,\n",
       " 0.93,\n",
       " 0.128,\n",
       " 0.0772,\n",
       " 0.8555,\n",
       " 0.128,\n",
       " -0.7579,\n",
       " -0.5994,\n",
       " -0.4939,\n",
       " 0.3167,\n",
       " 0.2846,\n",
       " 0.9348,\n",
       " 0.0534,\n",
       " 0.4019,\n",
       " 0.3415,\n",
       " 0.8271,\n",
       " 0.4019,\n",
       " 0.5106,\n",
       " -0.2382,\n",
       " 0.4767,\n",
       " -0.05,\n",
       " 0.8927,\n",
       " 0.8402,\n",
       " 0.0,\n",
       " 0.6486,\n",
       " 0.8573,\n",
       " 0.9136,\n",
       " 0.3612,\n",
       " 0.7783,\n",
       " 0.128,\n",
       " 0.4927,\n",
       " 0.8074,\n",
       " -0.3875,\n",
       " -0.8689,\n",
       " 0.296,\n",
       " 0.0,\n",
       " 0.8807,\n",
       " -0.1027,\n",
       " 0.4019,\n",
       " 0.8658,\n",
       " -0.1027,\n",
       " 0.2716,\n",
       " 0.4939,\n",
       " 0.0,\n",
       " 0.8225,\n",
       " 0.6054,\n",
       " 0.4767,\n",
       " 0.3862,\n",
       " 0.2732,\n",
       " 0.8126,\n",
       " 0.4939,\n",
       " 0.6124,\n",
       " -0.0387,\n",
       " 0.6124,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.336,\n",
       " 0.6808,\n",
       " 0.2263,\n",
       " 0.5859,\n",
       " -0.5423,\n",
       " 0.5574,\n",
       " 0.6625,\n",
       " 0.908,\n",
       " -0.5267,\n",
       " -0.7964,\n",
       " 0.9136,\n",
       " 0.5994,\n",
       " 0.8948,\n",
       " 0.8176,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.631,\n",
       " 0.431,\n",
       " 0.7964,\n",
       " -0.1531,\n",
       " 0.0516,\n",
       " -0.0258,\n",
       " 0.6369,\n",
       " 0.7579,\n",
       " 0.3626,\n",
       " 0.9169,\n",
       " 0.34,\n",
       " 0.0,\n",
       " 0.7184,\n",
       " 0.8731,\n",
       " 0.3818,\n",
       " 0.5423,\n",
       " 0.6369,\n",
       " 0.8921,\n",
       " -0.128,\n",
       " 0.5719,\n",
       " -0.25,\n",
       " 0.9001,\n",
       " 0.8271,\n",
       " 0.6705,\n",
       " 0.6249,\n",
       " -0.2023,\n",
       " 0.0,\n",
       " 0.7684,\n",
       " 0.7184,\n",
       " 0.6093,\n",
       " 0.802,\n",
       " 0.4215,\n",
       " 0.6858,\n",
       " 0.0,\n",
       " -0.5423,\n",
       " 0.8555,\n",
       " 0.228,\n",
       " 0.5994,\n",
       " 0.9178,\n",
       " 0.9252,\n",
       " -0.8316,\n",
       " 0.4215,\n",
       " 0.4678,\n",
       " 0.4939,\n",
       " 0.4404,\n",
       " -0.4926,\n",
       " -0.1263,\n",
       " 0.4215,\n",
       " 0.8885,\n",
       " -0.3612,\n",
       " 0.5719,\n",
       " -0.296,\n",
       " -0.1877,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2732,\n",
       " 0.5911,\n",
       " 0.6705,\n",
       " 0.0959,\n",
       " 0.5267,\n",
       " 0.836,\n",
       " 0.5423,\n",
       " 0.4767,\n",
       " -0.5334,\n",
       " 0.4215,\n",
       " 0.3182,\n",
       " 0.5859,\n",
       " 0.34,\n",
       " 0.5434,\n",
       " -0.4939,\n",
       " -0.4404,\n",
       " 0.8779,\n",
       " 0.2247,\n",
       " 0.0258,\n",
       " -0.4019,\n",
       " 0.3291,\n",
       " 0.7003,\n",
       " -0.5106,\n",
       " -0.8316,\n",
       " -0.5859,\n",
       " 0.4767,\n",
       " 0.2732,\n",
       " -0.2006,\n",
       " 0.128,\n",
       " 0.4215,\n",
       " 0.6369,\n",
       " 0.8176,\n",
       " 0.7717,\n",
       " -0.0772,\n",
       " 0.5106,\n",
       " 0.6213,\n",
       " -0.7783,\n",
       " 0.4215,\n",
       " 0.6249,\n",
       " 0.7783,\n",
       " 0.34,\n",
       " -0.5994,\n",
       " 0.0,\n",
       " 0.4404,\n",
       " 0.1584,\n",
       " 0.9201,\n",
       " 0.3269,\n",
       " 0.4019,\n",
       " 0.657,\n",
       " -0.659,\n",
       " -0.1695,\n",
       " 0.0129,\n",
       " 0.0,\n",
       " 0.9503,\n",
       " 0.6249,\n",
       " 0.5719,\n",
       " 0.0516,\n",
       " 0.4404,\n",
       " 0.5139,\n",
       " 0.5563,\n",
       " 0.8126,\n",
       " 0.7506,\n",
       " 0.4588,\n",
       " 0.2732,\n",
       " -0.1779,\n",
       " 0.891,\n",
       " 0.8074,\n",
       " 0.6249,\n",
       " 0.8677,\n",
       " 0.4927,\n",
       " 0.8573,\n",
       " 0.4939,\n",
       " -0.5423,\n",
       " 0.4767,\n",
       " 0.8519,\n",
       " 0.7351,\n",
       " 0.2023,\n",
       " 0.0498,\n",
       " 0.7579,\n",
       " 0.5719,\n",
       " 0.8658,\n",
       " 0.6597,\n",
       " -0.3182,\n",
       " 0.0,\n",
       " -0.296,\n",
       " 0.5994,\n",
       " 0.4767,\n",
       " 0.6705,\n",
       " -0.4404,\n",
       " 0.7351,\n",
       " 0.3802,\n",
       " 0.4939,\n",
       " 0.25,\n",
       " 0.0,\n",
       " 0.6597,\n",
       " 0.0,\n",
       " 0.9011,\n",
       " 0.0,\n",
       " 0.8225,\n",
       " 0.9042,\n",
       " 0.0,\n",
       " 0.7717,\n",
       " 0.0,\n",
       " 0.7841,\n",
       " 0.3818,\n",
       " 0.7351,\n",
       " 0.765,\n",
       " 0.0,\n",
       " 0.2732,\n",
       " 0.6249,\n",
       " -0.5106,\n",
       " -0.2263,\n",
       " 0.6486,\n",
       " 0.7184,\n",
       " 0.0,\n",
       " 0.6705,\n",
       " 0.0,\n",
       " 0.5423,\n",
       " 0.3818,\n",
       " 0.1803,\n",
       " 0.8271,\n",
       " 0.0,\n",
       " 0.6652,\n",
       " 0.7717,\n",
       " 0.4215,\n",
       " 0.7003,\n",
       " 0.3612,\n",
       " 0.6428,\n",
       " -0.8445,\n",
       " 0.8779,\n",
       " 0.875,\n",
       " 0.6249,\n",
       " 0.9354,\n",
       " 0.6808,\n",
       " 0.7269,\n",
       " 0.0,\n",
       " 0.5046,\n",
       " 0.4588,\n",
       " 0.0,\n",
       " 0.765,\n",
       " 0.0,\n",
       " -0.1753,\n",
       " 0.8689,\n",
       " 0.886,\n",
       " 0.8043,\n",
       " 0.4019,\n",
       " 0.6486,\n",
       " 0.4019,\n",
       " -0.3035,\n",
       " -0.2755,\n",
       " 0.34,\n",
       " 0.5719,\n",
       " 0.0,\n",
       " 0.8519,\n",
       " 0.4404,\n",
       " 0.0,\n",
       " 0.7845,\n",
       " 0.7269,\n",
       " 0.8745,\n",
       " -0.7717,\n",
       " 0.6124,\n",
       " 0.5106,\n",
       " 0.2263,\n",
       " 0.5267,\n",
       " -0.431,\n",
       " -0.4588,\n",
       " -0.6486,\n",
       " 0.8658,\n",
       " 0.5927,\n",
       " 0.5994,\n",
       " 0.6808,\n",
       " 0.5106,\n",
       " 0.0,\n",
       " 0.4019,\n",
       " 0.3612,\n",
       " 0.6124,\n",
       " 0.8176,\n",
       " 0.886,\n",
       " 0.7964,\n",
       " 0.7845,\n",
       " 0.3415,\n",
       " 0.0108,\n",
       " 0.1531,\n",
       " -0.6801,\n",
       " 0.0,\n",
       " 0.7003,\n",
       " 0.836,\n",
       " 0.3182,\n",
       " 0.8537,\n",
       " 0.891,\n",
       " 0.6597,\n",
       " 0.3818,\n",
       " 0.4728,\n",
       " 0.893,\n",
       " 0.7351,\n",
       " -0.6557,\n",
       " 0.7964,\n",
       " 0.5719,\n",
       " 0.25,\n",
       " -0.2023,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5499,\n",
       " 0.0,\n",
       " 0.4404,\n",
       " 0.6532,\n",
       " -0.7003,\n",
       " 0.2263,\n",
       " 0.802,\n",
       " 0.0,\n",
       " 0.836,\n",
       " 0.7579,\n",
       " 0.0,\n",
       " 0.7783,\n",
       " -0.0286,\n",
       " 0.5719,\n",
       " 0.0,\n",
       " 0.6705,\n",
       " 0.2732,\n",
       " 0.8255,\n",
       " 0.5873,\n",
       " -0.128,\n",
       " 0.4404,\n",
       " -0.5574,\n",
       " 0.4767,\n",
       " 0.4019,\n",
       " 0.8402,\n",
       " 0.7964,\n",
       " 0.3612,\n",
       " 0.0516,\n",
       " 0.8978,\n",
       " 0.6808,\n",
       " 0.0,\n",
       " 0.3182,\n",
       " 0.8367,\n",
       " 0.4019,\n",
       " -0.25,\n",
       " -0.4215,\n",
       " 0.743,\n",
       " 0.4019,\n",
       " 0.0,\n",
       " 0.5719,\n",
       " 0.0,\n",
       " 0.128,\n",
       " -0.3412,\n",
       " 0.6879,\n",
       " 0.7003,\n",
       " 0.3612,\n",
       " 0.9062,\n",
       " 0.3182,\n",
       " 0.4215,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0258,\n",
       " 0.5994,\n",
       " 0.9349,\n",
       " 0.0276,\n",
       " 0.3818,\n",
       " 0.1531,\n",
       " 0.659,\n",
       " 0.5688,\n",
       " 0.2263,\n",
       " 0.8979,\n",
       " 0.4404,\n",
       " 0.1531,\n",
       " 0.0762,\n",
       " 0.0258,\n",
       " 0.9041,\n",
       " 0.0,\n",
       " 0.4939,\n",
       " 0.3612,\n",
       " 0.9107,\n",
       " -0.0258,\n",
       " 0.5423,\n",
       " 0.5859,\n",
       " -0.8176,\n",
       " -0.4019,\n",
       " 0.0,\n",
       " -0.3687,\n",
       " 0.0,\n",
       " 0.1531,\n",
       " 0.5423,\n",
       " 0.6005,\n",
       " 0.6249,\n",
       " 0.3818,\n",
       " 0.7149,\n",
       " 0.3182,\n",
       " 0.8176,\n",
       " 0.0,\n",
       " 0.25,\n",
       " -0.4013,\n",
       " 0.4215,\n",
       " 0.296,\n",
       " 0.4404,\n",
       " 0.4939,\n",
       " 0.7003,\n",
       " 0.431,\n",
       " -0.1027,\n",
       " -0.1901,\n",
       " 0.25,\n",
       " -0.4549,\n",
       " 0.3612,\n",
       " 0.7184,\n",
       " -0.1027,\n",
       " 0.0,\n",
       " 0.2732,\n",
       " 0.5267,\n",
       " 0.6113,\n",
       " 0.1779,\n",
       " -0.2682,\n",
       " -0.25,\n",
       " 0.0,\n",
       " 0.6509,\n",
       " 0.6697,\n",
       " 0.0,\n",
       " 0.2023,\n",
       " 0.4215,\n",
       " 0.1655,\n",
       " -0.25,\n",
       " 0.4588,\n",
       " 0.8481,\n",
       " 0.4939,\n",
       " 0.7501,\n",
       " 0.0,\n",
       " 0.5423,\n",
       " 0.7845,\n",
       " 0.5994,\n",
       " -0.3818,\n",
       " 0.5719,\n",
       " 0.0,\n",
       " -0.3182,\n",
       " -0.8126,\n",
       " -0.128,\n",
       " 0.2263,\n",
       " 0.802,\n",
       " -0.4588,\n",
       " 0.1027,\n",
       " 0.0,\n",
       " -0.4939,\n",
       " 0.9674,\n",
       " 0.3182,\n",
       " 0.7964,\n",
       " 0.6249,\n",
       " 0.34,\n",
       " 0.2263,\n",
       " 0.836,\n",
       " 0.9062,\n",
       " 0.0276,\n",
       " -0.25,\n",
       " 0.7506,\n",
       " -0.2228,\n",
       " -0.3361,\n",
       " -0.1695,\n",
       " -0.9398,\n",
       " 0.8442,\n",
       " 0.4588,\n",
       " 0.6908,\n",
       " 0.0,\n",
       " 0.6249,\n",
       " -0.2472,\n",
       " 0.3818,\n",
       " 0.3392,\n",
       " 0.8603,\n",
       " -0.2732,\n",
       " 0.128,\n",
       " 0.5574,\n",
       " 0.765,\n",
       " -0.8176,\n",
       " 0.8847,\n",
       " 0.6486,\n",
       " -0.6597,\n",
       " 0.5574,\n",
       " 0.7227,\n",
       " -0.3612,\n",
       " 0.9062,\n",
       " 0.7184,\n",
       " -0.7783,\n",
       " 0.5267,\n",
       " 0.6369,\n",
       " 0.7096,\n",
       " -0.296,\n",
       " 0.8176,\n",
       " -0.4939,\n",
       " 0.6369,\n",
       " 0.5563,\n",
       " -0.0258,\n",
       " 0.5719,\n",
       " -0.5023,\n",
       " 0.4767,\n",
       " 0.6124,\n",
       " 0.1655,\n",
       " 0.4767,\n",
       " 0.0,\n",
       " 0.5106,\n",
       " 0.0,\n",
       " -0.0828,\n",
       " 0.6288,\n",
       " 0.7845,\n",
       " 0.3182,\n",
       " -0.1045,\n",
       " 0.8555,\n",
       " -0.4215,\n",
       " 0.6808,\n",
       " 0.91,\n",
       " 0.5106,\n",
       " 0.6808,\n",
       " 0.6369,\n",
       " 0.3612,\n",
       " 0.4404,\n",
       " 0.2023,\n",
       " 0.3612,\n",
       " 0.9186,\n",
       " 0.2016,\n",
       " 0.5859,\n",
       " -0.128,\n",
       " 0.4927,\n",
       " 0.0,\n",
       " 0.5423,\n",
       " 0.7717,\n",
       " -0.0772,\n",
       " 0.4588,\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vaderSentiment(onePositiveReview) for onePositiveReview in positiveReviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0258,\n",
       " 0.4404,\n",
       " 0.0,\n",
       " -0.25,\n",
       " 0.0,\n",
       " 0.4939,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.34,\n",
       " -0.3612,\n",
       " -0.3678,\n",
       " 0.397,\n",
       " -0.0384,\n",
       " -0.836,\n",
       " 0.3818,\n",
       " -0.2565,\n",
       " 0.4404,\n",
       " 0.4199,\n",
       " 0.0772,\n",
       " 0.0,\n",
       " 0.7346,\n",
       " -0.3559,\n",
       " 0.2732,\n",
       " -0.0516,\n",
       " 0.4939,\n",
       " 0.4019,\n",
       " -0.5423,\n",
       " -0.8887,\n",
       " 0.6068,\n",
       " -0.296,\n",
       " 0.0772,\n",
       " 0.0,\n",
       " 0.5267,\n",
       " 0.4939,\n",
       " -0.7845,\n",
       " -0.5865,\n",
       " 0.0258,\n",
       " -0.2457,\n",
       " -0.5789,\n",
       " 0.0,\n",
       " -0.25,\n",
       " -0.6808,\n",
       " 0.4588,\n",
       " 0.5574,\n",
       " 0.802,\n",
       " -0.4767,\n",
       " 0.6124,\n",
       " -0.4767,\n",
       " -0.7579,\n",
       " 0.0,\n",
       " -0.5562,\n",
       " 0.0516,\n",
       " 0.6369,\n",
       " -0.4767,\n",
       " -0.5574,\n",
       " 0.4404,\n",
       " 0.8658,\n",
       " 0.0,\n",
       " 0.3477,\n",
       " 0.5574,\n",
       " -0.8591,\n",
       " -0.5574,\n",
       " -0.5994,\n",
       " 0.128,\n",
       " 0.1154,\n",
       " 0.34,\n",
       " 0.2509,\n",
       " 0.4404,\n",
       " -0.4767,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.144,\n",
       " 0.4215,\n",
       " 0.0,\n",
       " 0.2846,\n",
       " -0.5267,\n",
       " 0.0,\n",
       " -0.0258,\n",
       " -0.2235,\n",
       " -0.4824,\n",
       " 0.5095,\n",
       " -0.4215,\n",
       " 0.4402,\n",
       " 0.4019,\n",
       " -0.7269,\n",
       " 0.0,\n",
       " 0.875,\n",
       " 0.4767,\n",
       " -0.3239,\n",
       " 0.1779,\n",
       " 0.8497,\n",
       " 0.4404,\n",
       " 0.0,\n",
       " 0.3612,\n",
       " 0.802,\n",
       " -0.1263,\n",
       " -0.3612,\n",
       " 0.5994,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.4391,\n",
       " -0.6369,\n",
       " 0.34,\n",
       " 0.2263,\n",
       " 0.0,\n",
       " 0.7715,\n",
       " -0.5096,\n",
       " -0.1263,\n",
       " -0.3612,\n",
       " -0.835,\n",
       " 0.2732,\n",
       " -0.4019,\n",
       " -0.8201,\n",
       " -0.6486,\n",
       " 0.0,\n",
       " -0.2382,\n",
       " 0.631,\n",
       " -0.6351,\n",
       " -0.3182,\n",
       " 0.0451,\n",
       " -0.4168,\n",
       " -0.2263,\n",
       " -0.2263,\n",
       " 0.4019,\n",
       " -0.296,\n",
       " 0.0,\n",
       " 0.1027,\n",
       " -0.3089,\n",
       " 0.0,\n",
       " 0.3612,\n",
       " 0.296,\n",
       " -0.4215,\n",
       " -0.3804,\n",
       " -0.3337,\n",
       " 0.6124,\n",
       " -0.2782,\n",
       " 0.0258,\n",
       " 0.4118,\n",
       " 0.3612,\n",
       " 0.2263,\n",
       " 0.4939,\n",
       " 0.3016,\n",
       " 0.4939,\n",
       " 0.9273,\n",
       " 0.785,\n",
       " 0.5106,\n",
       " -0.5423,\n",
       " 0.5267,\n",
       " 0.0,\n",
       " 0.743,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.8074,\n",
       " -0.4019,\n",
       " 0.4767,\n",
       " 0.4939,\n",
       " -0.6077,\n",
       " -0.296,\n",
       " -0.5106,\n",
       " 0.4555,\n",
       " 0.7184,\n",
       " 0.0258,\n",
       " -0.6369,\n",
       " -0.4404,\n",
       " 0.0258,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.6501,\n",
       " -0.2732,\n",
       " 0.6038,\n",
       " -0.5574,\n",
       " -0.4991,\n",
       " 0.4019,\n",
       " -0.4404,\n",
       " 0.0,\n",
       " -0.865,\n",
       " 0.0,\n",
       " 0.7234,\n",
       " -0.4404,\n",
       " -0.3182,\n",
       " -0.5095,\n",
       " -0.4717,\n",
       " 0.7579,\n",
       " 0.0258,\n",
       " -0.25,\n",
       " -0.0516,\n",
       " 0.2846,\n",
       " 0.836,\n",
       " 0.0,\n",
       " 0.6369,\n",
       " -0.4497,\n",
       " 0.0,\n",
       " -0.1779,\n",
       " -0.4939,\n",
       " 0.1531,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.6397,\n",
       " -0.5574,\n",
       " 0.775,\n",
       " 0.0258,\n",
       " -0.7506,\n",
       " -0.2183,\n",
       " -0.0516,\n",
       " 0.25,\n",
       " -0.76,\n",
       " -0.3412,\n",
       " 0.0,\n",
       " 0.296,\n",
       " -0.6808,\n",
       " -0.4173,\n",
       " 0.2272,\n",
       " 0.4588,\n",
       " 0.5859,\n",
       " 0.2052,\n",
       " -0.7096,\n",
       " 0.875,\n",
       " -0.2484,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1027,\n",
       " -0.0129,\n",
       " -0.3818,\n",
       " 0.6428,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.7717,\n",
       " -0.6249,\n",
       " 0.0,\n",
       " -0.6249,\n",
       " -0.09,\n",
       " -0.3252,\n",
       " 0.6486,\n",
       " 0.0118,\n",
       " 0.0,\n",
       " -0.4939,\n",
       " 0.6027,\n",
       " 0.6059,\n",
       " -0.5574,\n",
       " 0.5574,\n",
       " 0.6779,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.1027,\n",
       " -0.0772,\n",
       " -0.2078,\n",
       " 0.2263,\n",
       " 0.0,\n",
       " 0.0772,\n",
       " 0.3182,\n",
       " 0.8617,\n",
       " -0.5106,\n",
       " 0.1531,\n",
       " -0.7184,\n",
       " 0.0,\n",
       " -0.1027,\n",
       " 0.4939,\n",
       " -0.4215,\n",
       " -0.743,\n",
       " 0.0,\n",
       " 0.1779,\n",
       " -0.5423,\n",
       " 0.0,\n",
       " 0.4492,\n",
       " 0.3182,\n",
       " -0.3089,\n",
       " 0.4404,\n",
       " 0.5499,\n",
       " 0.2259,\n",
       " -0.2462,\n",
       " 0.0,\n",
       " -0.802,\n",
       " -0.765,\n",
       " 0.0258,\n",
       " 0.0258,\n",
       " -0.8885,\n",
       " 0.0,\n",
       " -0.7351,\n",
       " 0.3612,\n",
       " -0.4404,\n",
       " 0.4995,\n",
       " 0.3182,\n",
       " -0.34,\n",
       " 0.7517,\n",
       " 0.8126,\n",
       " 0.7693,\n",
       " 0.1984,\n",
       " 0.3818,\n",
       " -0.8885,\n",
       " -0.2074,\n",
       " 0.0,\n",
       " -0.25,\n",
       " -0.34,\n",
       " -0.1779,\n",
       " 0.0067,\n",
       " -0.6765,\n",
       " 0.0,\n",
       " 0.6124,\n",
       " 0.4215,\n",
       " 0.0,\n",
       " -0.5267,\n",
       " -0.6606,\n",
       " 0.3818,\n",
       " 0.8225,\n",
       " 0.25,\n",
       " -0.743,\n",
       " -0.1531,\n",
       " -0.6361,\n",
       " 0.8769,\n",
       " 0.7897,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.3412,\n",
       " -0.0516,\n",
       " 0.1901,\n",
       " 0.5859,\n",
       " 0.1901,\n",
       " 0.1531,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5994,\n",
       " 0.25,\n",
       " -0.34,\n",
       " 0.875,\n",
       " -0.2926,\n",
       " 0.3632,\n",
       " -0.5267,\n",
       " -0.4939,\n",
       " 0.2732,\n",
       " 0.0,\n",
       " -0.5106,\n",
       " -0.6124,\n",
       " 0.4144,\n",
       " 0.0772,\n",
       " 0.0,\n",
       " 0.4724,\n",
       " -0.2023,\n",
       " 0.0,\n",
       " 0.4588,\n",
       " -0.6808,\n",
       " 0.0,\n",
       " 0.1126,\n",
       " 0.25,\n",
       " -0.25,\n",
       " 0.0,\n",
       " -0.4497,\n",
       " 0.2263,\n",
       " -0.1779,\n",
       " 0.0,\n",
       " 0.128,\n",
       " -0.3744,\n",
       " 0.0818,\n",
       " 0.2732,\n",
       " 0.5719,\n",
       " 0.0,\n",
       " 0.2865,\n",
       " 0.5859,\n",
       " 0.8176,\n",
       " 0.6369,\n",
       " 0.5859,\n",
       " 0.2922,\n",
       " 0.0,\n",
       " -0.5256,\n",
       " -0.3182,\n",
       " 0.2144,\n",
       " 0.0,\n",
       " 0.3612,\n",
       " 0.0,\n",
       " -0.0772,\n",
       " 0.6369,\n",
       " -0.5994,\n",
       " 0.0,\n",
       " 0.4404,\n",
       " 0.1154,\n",
       " 0.5063,\n",
       " 0.25,\n",
       " 0.8004,\n",
       " 0.3597,\n",
       " -0.3182,\n",
       " -0.3818,\n",
       " 0.6249,\n",
       " 0.0,\n",
       " 0.4404,\n",
       " 0.0,\n",
       " -0.8074,\n",
       " 0.6705,\n",
       " 0.25,\n",
       " 0.0,\n",
       " -0.1531,\n",
       " 0.4404,\n",
       " 0.5106,\n",
       " -0.4588,\n",
       " 0.0,\n",
       " 0.541,\n",
       " 0.0387,\n",
       " -0.8316,\n",
       " 0.4019,\n",
       " 0.0,\n",
       " 0.1779,\n",
       " 0.0772,\n",
       " 0.3612,\n",
       " 0.3612,\n",
       " 0.1531,\n",
       " 0.8511,\n",
       " 0.0,\n",
       " 0.128,\n",
       " 0.2263,\n",
       " 0.6435,\n",
       " 0.501,\n",
       " -0.5429,\n",
       " -0.8501,\n",
       " -0.4767,\n",
       " 0.4215,\n",
       " 0.7845,\n",
       " -0.3818,\n",
       " 0.3724,\n",
       " -0.8031,\n",
       " 0.296,\n",
       " 0.5859,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1027,\n",
       " -0.5719,\n",
       " 0.431,\n",
       " 0.1027,\n",
       " -0.7906,\n",
       " 0.0772,\n",
       " 0.4939,\n",
       " -0.25,\n",
       " 0.5859,\n",
       " -0.8658,\n",
       " 0.4497,\n",
       " 0.0,\n",
       " -0.296,\n",
       " 0.0,\n",
       " -0.5106,\n",
       " 0.5267,\n",
       " -0.5719,\n",
       " 0.6597,\n",
       " 0.0,\n",
       " 0.4019,\n",
       " -0.743,\n",
       " 0.3612,\n",
       " -0.6124,\n",
       " 0.0,\n",
       " -0.296,\n",
       " 0.0,\n",
       " 0.765,\n",
       " 0.6868,\n",
       " 0.3612,\n",
       " 0.8626,\n",
       " 0.296,\n",
       " -0.0077,\n",
       " 0.0,\n",
       " -0.3182,\n",
       " 0.25,\n",
       " 0.0,\n",
       " -0.7906,\n",
       " 0.6369,\n",
       " 0.8957,\n",
       " 0.736,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0834,\n",
       " 0.0772,\n",
       " 0.2382,\n",
       " -0.1045,\n",
       " 0.0,\n",
       " 0.1531,\n",
       " -0.4019,\n",
       " -0.2732,\n",
       " -0.3612,\n",
       " 0.6378,\n",
       " -0.8225,\n",
       " -0.34,\n",
       " -0.25,\n",
       " -0.3612,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.2732,\n",
       " -0.3818,\n",
       " 0.5106,\n",
       " 0.0,\n",
       " 0.7184,\n",
       " -0.3612,\n",
       " 0.6486,\n",
       " 0.0,\n",
       " 0.2023,\n",
       " -0.7645,\n",
       " 0.4336,\n",
       " -0.3612,\n",
       " 0.4939,\n",
       " -0.1298,\n",
       " 0.4767,\n",
       " -0.2732,\n",
       " -0.2023,\n",
       " -0.4588,\n",
       " 0.0,\n",
       " -0.6602,\n",
       " 0.6251,\n",
       " -0.6249,\n",
       " 0.1531,\n",
       " 0.4019,\n",
       " 0.5574,\n",
       " 0.0,\n",
       " 0.3818,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2263,\n",
       " 0.0,\n",
       " 0.3182,\n",
       " -0.9252,\n",
       " 0.0,\n",
       " 0.7884,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.1027,\n",
       " 0.5574,\n",
       " 0.2111,\n",
       " -0.5423,\n",
       " 0.0,\n",
       " 0.3612,\n",
       " 0.2732,\n",
       " 0.6856,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.296,\n",
       " 0.6932,\n",
       " 0.0,\n",
       " 0.0258,\n",
       " -0.765,\n",
       " 0.5145,\n",
       " 0.4019,\n",
       " 0.0516,\n",
       " -0.34,\n",
       " 0.2732,\n",
       " 0.4215,\n",
       " -0.4404,\n",
       " 0.3707,\n",
       " 0.7579,\n",
       " -0.5446,\n",
       " -0.0972,\n",
       " 0.4019,\n",
       " 0.5627,\n",
       " 0.0,\n",
       " -0.3919,\n",
       " 0.8176,\n",
       " 0.0,\n",
       " 0.818,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6231,\n",
       " 0.6187,\n",
       " 0.397,\n",
       " 0.9246,\n",
       " 0.5267,\n",
       " 0.836,\n",
       " -0.6326,\n",
       " 0.3182,\n",
       " 0.5096,\n",
       " 0.6077,\n",
       " 0.0,\n",
       " -0.4215,\n",
       " -0.4019,\n",
       " -0.3138,\n",
       " 0.4574,\n",
       " 0.8979,\n",
       " 0.7003,\n",
       " 0.7184,\n",
       " -0.7096,\n",
       " 0.8294,\n",
       " 0.0,\n",
       " -0.4404,\n",
       " 0.0757,\n",
       " 0.8481,\n",
       " 0.1779,\n",
       " 0.3291,\n",
       " -0.4527,\n",
       " 0.0258,\n",
       " 0.0697,\n",
       " -0.7717,\n",
       " 0.4159,\n",
       " -0.6486,\n",
       " 0.0,\n",
       " -0.1531,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.3612,\n",
       " -0.7184,\n",
       " 0.4585,\n",
       " 0.0,\n",
       " -0.2732,\n",
       " -0.836,\n",
       " -0.5106,\n",
       " -0.4971,\n",
       " -0.1298,\n",
       " -0.1136,\n",
       " 0.0,\n",
       " 0.1531,\n",
       " -0.4404,\n",
       " -0.6808,\n",
       " -0.0516,\n",
       " -0.8173,\n",
       " 0.7783,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0772,\n",
       " -0.4023,\n",
       " 0.2263,\n",
       " -0.5423,\n",
       " -0.7469,\n",
       " -0.2732,\n",
       " 0.5023,\n",
       " -0.6808,\n",
       " -0.9169,\n",
       " -0.3182,\n",
       " -0.4767,\n",
       " -0.128,\n",
       " 0.1779,\n",
       " 0.0,\n",
       " 0.1779,\n",
       " -0.2201,\n",
       " 0.6943,\n",
       " 0.0276,\n",
       " 0.1526,\n",
       " 0.0,\n",
       " -0.6369,\n",
       " -0.8553,\n",
       " -0.34,\n",
       " -0.5994,\n",
       " 0.7425,\n",
       " 0.2382,\n",
       " -0.296,\n",
       " 0.0,\n",
       " 0.5423,\n",
       " 0.2732,\n",
       " 0.6249,\n",
       " -0.3612,\n",
       " -0.0258,\n",
       " 0.4019,\n",
       " -0.3612,\n",
       " -0.5023,\n",
       " 0.2144,\n",
       " 0.5574,\n",
       " -0.2023,\n",
       " 0.6858,\n",
       " 0.3412,\n",
       " 0.0,\n",
       " 0.8462,\n",
       " 0.0,\n",
       " -0.6297,\n",
       " 0.1531,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.3182,\n",
       " -0.4215,\n",
       " -0.3612,\n",
       " 0.2846,\n",
       " 0.0,\n",
       " 0.7964,\n",
       " -0.4404,\n",
       " 0.0,\n",
       " 0.3182,\n",
       " -0.8074,\n",
       " 0.2609,\n",
       " -0.7964,\n",
       " 0.3612,\n",
       " -0.1531,\n",
       " -0.5334,\n",
       " 0.2382,\n",
       " 0.0,\n",
       " 0.1027,\n",
       " 0.3291,\n",
       " 0.2944,\n",
       " 0.0,\n",
       " -0.4404,\n",
       " 0.1779,\n",
       " -0.6908,\n",
       " 0.8218,\n",
       " 0.7096,\n",
       " 0.0,\n",
       " -0.5106,\n",
       " -0.1285,\n",
       " 0.34,\n",
       " 0.4927,\n",
       " 0.6705,\n",
       " 0.1139,\n",
       " 0.2732,\n",
       " 0.0,\n",
       " 0.7771,\n",
       " 0.0,\n",
       " 0.3839,\n",
       " 0.3612,\n",
       " -0.1531,\n",
       " -0.5423,\n",
       " 0.0,\n",
       " 0.8834,\n",
       " -0.5574,\n",
       " 0.4744,\n",
       " 0.0,\n",
       " 0.2023,\n",
       " 0.6094,\n",
       " 0.5106,\n",
       " 0.0,\n",
       " -0.0516,\n",
       " 0.3016,\n",
       " -0.5719,\n",
       " -0.6124,\n",
       " -0.8316,\n",
       " 0.0191,\n",
       " 0.5994,\n",
       " 0.0,\n",
       " -0.5719,\n",
       " -0.4019,\n",
       " 0.0,\n",
       " 0.5859,\n",
       " -0.5563,\n",
       " -0.34,\n",
       " 0.4404,\n",
       " 0.0,\n",
       " 0.4215,\n",
       " -0.128,\n",
       " -0.3612,\n",
       " -0.7876,\n",
       " -0.25,\n",
       " 0.5719,\n",
       " 0.5994,\n",
       " 0.1994,\n",
       " 0.0,\n",
       " 0.4588,\n",
       " 0.3716,\n",
       " -0.8481,\n",
       " -0.8292,\n",
       " -0.4927,\n",
       " 0.2144,\n",
       " -0.7579,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5423,\n",
       " 0.0,\n",
       " -0.3559,\n",
       " -0.6956,\n",
       " -0.8971,\n",
       " 0.4287,\n",
       " -0.5106,\n",
       " 0.1531,\n",
       " 0.5994,\n",
       " -0.4019,\n",
       " -0.8519,\n",
       " 0.6696,\n",
       " 0.0258,\n",
       " 0.0,\n",
       " -0.128,\n",
       " -0.5733,\n",
       " 0.0,\n",
       " -0.5423,\n",
       " 0.0387,\n",
       " -0.1779,\n",
       " 0.2006,\n",
       " -0.5499,\n",
       " 0.3673,\n",
       " 0.0,\n",
       " 0.2732,\n",
       " -0.7346,\n",
       " -0.2732,\n",
       " 0.5994,\n",
       " 0.6124,\n",
       " -0.0772,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.1189,\n",
       " 0.802,\n",
       " 0.6908,\n",
       " 0.296,\n",
       " 0.6249,\n",
       " -0.4588,\n",
       " -0.2565,\n",
       " 0.3818,\n",
       " -0.1027,\n",
       " -0.4404,\n",
       " -0.5994,\n",
       " 0.3682,\n",
       " 0.0,\n",
       " -0.8885,\n",
       " -0.5267,\n",
       " 0.5423,\n",
       " -0.785,\n",
       " -0.6808,\n",
       " -0.3182,\n",
       " -0.6908,\n",
       " 0.0,\n",
       " 0.6486,\n",
       " 0.7351,\n",
       " -0.0772,\n",
       " 0.0,\n",
       " -0.1119,\n",
       " 0.6249,\n",
       " 0.3612,\n",
       " 0.1027,\n",
       " -0.6361,\n",
       " 0.0,\n",
       " -0.4404,\n",
       " 0.3818,\n",
       " -0.34,\n",
       " -0.3612,\n",
       " 0.4118,\n",
       " 0.8174,\n",
       " 0.2732,\n",
       " -0.7845,\n",
       " 0.5719,\n",
       " 0.0,\n",
       " -0.6369,\n",
       " -0.7346,\n",
       " -0.4019,\n",
       " 0.0,\n",
       " 0.7026,\n",
       " 0.1655,\n",
       " 0.0258,\n",
       " 0.2023,\n",
       " 0.09,\n",
       " -0.7845,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.3612,\n",
       " -0.7506,\n",
       " -0.7501,\n",
       " 0.0,\n",
       " -0.7184,\n",
       " -0.6486,\n",
       " -0.68,\n",
       " 0.0,\n",
       " -0.6124,\n",
       " -0.6705,\n",
       " -0.1015,\n",
       " -0.128,\n",
       " 0.0,\n",
       " 0.3811,\n",
       " 0.926,\n",
       " -0.2732,\n",
       " -0.471,\n",
       " 0.4215,\n",
       " -0.2023,\n",
       " 0.8225,\n",
       " 0.6369,\n",
       " -0.0909,\n",
       " 0.296,\n",
       " 0.0258,\n",
       " 0.7906,\n",
       " -0.687,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1706,\n",
       " 0.5719,\n",
       " 0.0,\n",
       " -0.4549,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.3612,\n",
       " -0.34,\n",
       " 0.7717,\n",
       " 0.0,\n",
       " -0.6485,\n",
       " -0.1043,\n",
       " -0.4215,\n",
       " -0.0459,\n",
       " 0.3612,\n",
       " 0.0,\n",
       " -0.4215,\n",
       " 0.3818,\n",
       " 0.1227,\n",
       " 0.5994,\n",
       " 0.5106,\n",
       " 0.4767,\n",
       " 0.0,\n",
       " 0.0772,\n",
       " -0.4215,\n",
       " -0.6771,\n",
       " 0.2846,\n",
       " 0.0772,\n",
       " -0.3612,\n",
       " 0.3291,\n",
       " -0.7506,\n",
       " 0.8201,\n",
       " 0.4588,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.7845,\n",
       " 0.0,\n",
       " 0.5574,\n",
       " 0.0,\n",
       " -0.431,\n",
       " -0.1869,\n",
       " 0.8998,\n",
       " 0.0,\n",
       " -0.6897,\n",
       " -0.3477,\n",
       " -0.25,\n",
       " -0.0516,\n",
       " -0.5719,\n",
       " -0.8689,\n",
       " -0.6369,\n",
       " 0.8176,\n",
       " 0.0,\n",
       " -0.3896,\n",
       " 0.4019,\n",
       " 0.3612,\n",
       " -0.2263,\n",
       " -0.4588,\n",
       " -0.411,\n",
       " 0.6956,\n",
       " -0.6249,\n",
       " -0.7015,\n",
       " -0.5267,\n",
       " -0.3976,\n",
       " 0.296,\n",
       " 0.4215,\n",
       " -0.836,\n",
       " 0.4404,\n",
       " 0.0,\n",
       " 0.5267,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.101,\n",
       " -0.1027,\n",
       " -0.8316,\n",
       " -0.4767,\n",
       " 0.4767,\n",
       " 0.4019,\n",
       " -0.128,\n",
       " 0.0,\n",
       " 0.2732,\n",
       " -0.5078,\n",
       " 0.5859,\n",
       " -0.296,\n",
       " -0.192,\n",
       " -0.6492,\n",
       " 0.4497,\n",
       " -0.0516,\n",
       " -0.2023,\n",
       " 0.0,\n",
       " -0.4588,\n",
       " 0.6486,\n",
       " 0.2263,\n",
       " 0.3415,\n",
       " 0.2681,\n",
       " -0.5267,\n",
       " 0.3612,\n",
       " 0.0,\n",
       " 0.6486,\n",
       " 0.0,\n",
       " 0.1027,\n",
       " 0.5859,\n",
       " -0.3089,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.7994,\n",
       " -0.4404,\n",
       " -0.4215,\n",
       " 0.0,\n",
       " -0.34,\n",
       " 0.5423,\n",
       " 0.4588,\n",
       " 0.6597,\n",
       " 0.128,\n",
       " -0.4019,\n",
       " 0.0258,\n",
       " 0.0,\n",
       " 0.7605,\n",
       " -0.7717,\n",
       " 0.0,\n",
       " 0.296,\n",
       " 0.0018,\n",
       " 0.2732,\n",
       " 0.2732,\n",
       " -0.5367,\n",
       " -0.8074,\n",
       " -0.34,\n",
       " 0.6808,\n",
       " 0.0422,\n",
       " 0.2363,\n",
       " -0.4019,\n",
       " 0.0,\n",
       " -0.8353,\n",
       " -0.6486,\n",
       " -0.836,\n",
       " 0.0,\n",
       " 0.4201,\n",
       " 0.0,\n",
       " 0.1406,\n",
       " 0.4019,\n",
       " 0.2732,\n",
       " 0.0,\n",
       " 0.5898,\n",
       " 0.0,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vaderSentiment(oneNegativeReview) for oneNegativeReview in negativeReviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vaderResults = getReviewSentiments(vaderSentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['results-on-positive', 'results-on-negative'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaderResults.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vaderResults['results-on-positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vaderResults['results-on-negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3612"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaderResults['results-on-positive'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0258"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaderResults['results-on-negative'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runDiagnostics(viewResult):\n",
    "    positiveReviewsResult = vaderResults['results-on-positive']\n",
    "    negativeReviewsResult = vaderResults['results-on-negative']\n",
    "    pctTruePositive = float(sum(x > 0 for x in positiveReviewsResult)) / len(positiveReviewsResult)\n",
    "    pctTrueNegative = float(sum(x < 0 for x in negativeReviewsResult)) / len(negativeReviewsResult)\n",
    "    totalAccurate = float(sum(x > 0 for x in positiveReviewsResult)) + float(sum(x < 0 for x in negativeReviewsResult))\n",
    "    total = len(positiveReviewsResult) + len(negativeReviewsResult)\n",
    "    print(\"Accuracy on positive reviews = \" + \"%.2f\" % (pctTruePositive*100) + \"%\")\n",
    "    print(\"Accuracy on negative reviews = \" + \"%.2f\" % (pctTrueNegative*100) + \"%\")\n",
    "    print(\"Overall accuracy = \" + \"%.2f\" % (totalAccurate*100/total) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on positive reviews = 69.44%\n",
      "Accuracy on negative reviews = 40.09%\n",
      "Overall accuracy = 54.76%\n"
     ]
    }
   ],
   "source": [
    "runDiagnostics(getReviewSentiments(vaderSentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sentiword\n",
    "### - Sentiment lexicon with polarity information.\n",
    "### - Built into pythn nltk.\n",
    "### - Extends wordnet (A large lexical database in english. A word can have many meanings and all those meanings must be linked to that word in some way)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wordnet\n",
    "### * Word; Lemma - each meaning of a particular word; Synset - synonym set to represent all words that share a particular meaning.\n",
    "### Example :-\n",
    "### Word ----> Dog\n",
    "### Lemma1: - Pet(noun) ; Synset1 -:- Cat, hamster, etc;\n",
    "### Lemma2: - follow (verb) ; Synset1 -:- stalk, persue etc;\n",
    "### Lemma3: - cheat (noun); Synset1 -:- Cad, bounder, etc;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How sentiword uses wordnet?\n",
    "#### It assigns polarities to each synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<filter at 0xb306630>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "swn.senti_synsets('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01'),\n",
       " Synset('chase.v.01')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dog = wn.synsets('dog')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'domestic_dog', 'Canis_familiaris']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.pos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '_all_hypernyms',\n",
       " '_definition',\n",
       " '_examples',\n",
       " '_frame_ids',\n",
       " '_hypernyms',\n",
       " '_instance_hypernyms',\n",
       " '_iter_hypernym_lists',\n",
       " '_lemma_names',\n",
       " '_lemma_pointers',\n",
       " '_lemmas',\n",
       " '_lexname',\n",
       " '_max_depth',\n",
       " '_min_depth',\n",
       " '_name',\n",
       " '_needs_root',\n",
       " '_offset',\n",
       " '_pointers',\n",
       " '_pos',\n",
       " '_related',\n",
       " '_shortest_hypernym_paths',\n",
       " '_wordnet_corpus_reader',\n",
       " 'also_sees',\n",
       " 'attributes',\n",
       " 'causes',\n",
       " 'closure',\n",
       " 'common_hypernyms',\n",
       " 'definition',\n",
       " 'entailments',\n",
       " 'examples',\n",
       " 'frame_ids',\n",
       " 'hypernym_distances',\n",
       " 'hypernym_paths',\n",
       " 'hypernyms',\n",
       " 'hyponyms',\n",
       " 'instance_hypernyms',\n",
       " 'instance_hyponyms',\n",
       " 'jcn_similarity',\n",
       " 'lch_similarity',\n",
       " 'lemma_names',\n",
       " 'lemmas',\n",
       " 'lexname',\n",
       " 'lin_similarity',\n",
       " 'lowest_common_hypernyms',\n",
       " 'max_depth',\n",
       " 'member_holonyms',\n",
       " 'member_meronyms',\n",
       " 'min_depth',\n",
       " 'name',\n",
       " 'offset',\n",
       " 'part_holonyms',\n",
       " 'part_meronyms',\n",
       " 'path_similarity',\n",
       " 'pos',\n",
       " 'region_domains',\n",
       " 'res_similarity',\n",
       " 'root_hypernyms',\n",
       " 'shortest_path_distance',\n",
       " 'similar_tos',\n",
       " 'substance_holonyms',\n",
       " 'substance_meronyms',\n",
       " 'topic_domains',\n",
       " 'tree',\n",
       " 'unicode_repr',\n",
       " 'usage_domains',\n",
       " 'verb_groups',\n",
       " 'wup_similarity']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving Sentiment Analysis with an ML-based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The working of the ML based clasifier is based on the features on which it is focused;\n",
    "#### ML_based (ML-based systems tend to do better if 'trained' with the right data.)\n",
    "##### * Dynamic\n",
    "##### * Experts optional\n",
    "##### * Corpus required\n",
    "##### * Training Step\n",
    "######  ------------------------------------------------------------------------------------------------------------------------\n",
    "#### Rule_Based (Rule-based analyzers often struggle with context.)\n",
    "##### * Static\n",
    "##### * Experts required\n",
    "##### * Corpus optional\n",
    "##### * No training step\n",
    "######  ------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuition Behind Bayes Theorem:\n",
    "#### i. A Priori Probabilities - Probabilities known before specifics about the person is known.\n",
    "#### ii. Conditional Probabilities - Specific items appear more often with one category than with the other.\n",
    "\n",
    "#### Applying Bayes theorem:\n",
    "##### Step 1: Find the probability that this person is a runner:\n",
    "##### P(Runner/Handcuffs, Badge) = Probability that a person carrying handcuffs and a badge is a runner;\n",
    "###### ----------------------------------------\n",
    "##### Step 2: Find the probability that this person is a police officer:\n",
    "##### P(Police Officier/Handcuffs, Badge) = Probability that a person carrying handcuffs and a badge is a police officer.\n",
    "###### ----------------------------------------\n",
    "##### Step 3: Pick the label with the higher probability\n",
    "##### Compare  P(Police Officier/Handcuffs, Badge) with P(Runner/Handcuffs, Badge)\n",
    "###### -------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes for Classification Problems\n",
    "#### Supervised learning ML algorithm.\n",
    "#### Training Data --------> Classification Algorithm --------------> ML-based Classifier;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -----------------------------------------------------\n",
    "### * Training Data \n",
    "##### Apply Bayes theorem to probability information from the training data to classify problem instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### ---------------------\n",
    "# Reviews                                              |Labels\n",
    "# Amazing!                                             |Positive\n",
    "# Worst movie ever                                     |Negative\n",
    "# Two thumbs up                                        |Positive\n",
    "# Part 2 was bad, 3 worst                              |Negative\n",
    "# Up there with the greats                             |Positive\n",
    "##### -----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### * A Priori Probabilities\n",
    "#### Observation 1 : - There are more positive reviews than negative reviews in the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Reviews  | occurences\n",
    "#  Positive | 3\n",
    "#  Negative | 2\n",
    "#  Total    | 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A priori probabilities - before anything specific about review contents is known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reviews  | occurences\n",
    "# Positive | 3/5\n",
    "# Negative | 2/5\n",
    "# Total    | 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------\n",
    "### * Conditional Probabilities\n",
    "#### Observation 2: Specific words occur more in one type of review than in other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reviews                                              |Labels\n",
    "# Amazing!                                             |Positive\n",
    "# Worst movie ever                                     |Negative\n",
    "# Two thumbs up                                        |Positive\n",
    "# Part 2 was bad, 3 worst                              |Negative\n",
    "# Up there with the greats                             |Positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The word 'up' appears twice in positive reviews, but zero times in negative reviews;\n",
    "#### The word 'worst' appears twice in negative reviews, and zero times in positive reviews;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WORD                   Occurence in                  Occurence in\n",
    "##                       Positive Reviews              Negative Reviews\n",
    "#1. amazing                   1\n",
    "#2. worst                                                    2\n",
    "#3. movie                                                    1\n",
    "#4. ever                                                     1\n",
    "#5. two                       1                              1\n",
    "#6. thumbs                    1\n",
    "#7. up                        2\n",
    "#8. part                                                     1 \n",
    "#9. was                                                      1 \n",
    "#10. bad                                                     1\n",
    "#11. 3                                                       1 \n",
    "#12. the                       1                             1\n",
    "#13.there                      1\n",
    "#14. with                      1 \n",
    "#15. greats                    1\n",
    "# ---------                   ---                            ---\n",
    "# TOTAL                        9                             10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P(text contains\"amazing\"/label = Positive) = 1/9\n",
    "#### P(text contains\"amazing\"/label = Negative) = 0\n",
    "\n",
    "#### P(text contains\"worst\"/label = Positive) = 0\n",
    "#### P(text contains\"worst\"/label = Positive) = 2/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Conditional Probability\n",
    "## ----------------------------------------------------------------------\n",
    "## WORD                   Occurence in                  Occurence in\n",
    "##                       Positive Reviews              Negative Reviews\n",
    "#1. amazing                   1/9\n",
    "#2. worst                                                    2/10\n",
    "#3. movie                                                    1/10\n",
    "#4. ever                                                     1/10\n",
    "#5. two                       1/9                            1/10\n",
    "#6. thumbs                    1/9\n",
    "#7. up                        2/9\n",
    "#8. part                                                     1/10 \n",
    "#9. was                                                      1/10 \n",
    "#10. bad                                                     1/10\n",
    "#11. 3                                                       1/10 \n",
    "#12. the                       1/9                           1/10\n",
    "#13.there                      1/9\n",
    "#14. with                      1/9 \n",
    "#15. greats                    1/9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Bayes Theorem\n",
    "\n",
    "#### (P(t/positive) * P(positive)) - Conditional proability X a priori probability;\n",
    "\n",
    "\n",
    "#### t = \"Really bad, the worst\";\n",
    "\n",
    "#### Step 1: Find the probability that the review is actually positive, given the text of the review (use Bayes Theorem)\n",
    "##### P(Positive/t) = P(label = Positive/text =  \"Really bad, the worst\");\n",
    "##### P(Positive/t) = (P(t/positive) * P(positive)) / (P(t/positive) * P(positive) + P(t/negative) * P(negative))\n",
    "\n",
    "#### Step 2: Find the probability that the review is actually negative, given the text of the review (use Bayes Theorem)\n",
    "##### P(Negative/t) = P(label = Negative/text =  \"Really bad, the worst\")\n",
    "##### P(Negative/t) = (P(t/Negative) * P(Negative)) / (P(t/positive) * P(positive) + P(t/negative) * P(negative))\n",
    "\n",
    "#### Step 3: Pick the label with higher probability\n",
    "##### If P(Positive/t) > P(Negative/t)\n",
    "######    classify t as Positive\n",
    "####  else\n",
    "######    classify t as Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------------------------------------------------------------------------------------\n",
    "### Apply Bayes Theorem\n",
    "#### t = \"Really bad, the worst\";\n",
    "\n",
    "#### conditional positive for t -  0 X 1/10 X 0 = 0; // really is not in list - ignored;\n",
    "#### conditional negative for t - 1/10 X 1/10 X 2/10 = 2/1000;\n",
    "\n",
    "\n",
    "#### P(Positive/t) = (P(t/positive) * P(positive)) / (P(t/positive) * P(positive) + P(t/negative) * P(negative))\n",
    "#### P(Positive/t) = 0 X 3/5\n",
    "#### ------------------------------------------\n",
    "#### P(Negative/t) = (P(t/Negative) * P(Negative)) / (P(t/positive) * P(positive) + P(t/negative) * P(negative))\n",
    "#### P(Negative/t) = 2/1000 X 2/5\n",
    "\n",
    "#### t = \"Really bad, the worst\"; -- labelled 'Negative';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------------------------------------------------------------------------------------\n",
    "### Support Vector Machines for Classification Problems\n",
    "##### i. SVM - more complicated, harder to understand and to use;\n",
    "##### ii. Naive Bayes often work well as well -  even with minimal tuning or tweaking;\n",
    "##### iii. SVM needs a lot of tuning - Parameter tuning makes all the differenve in SVM;\n",
    "###### ----------------------------\n",
    "##### SVM classifiers are incredibly hard to build, but fairly easy to use;\n",
    "##### Kernel functions are key to building SVM classifiers;\n",
    "##### Feature vectors are key to using SVM classfiers;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segreagation of data - classification of data:\n",
    "#### 1. Data in one dimension - Unidimensional data can be separated, classified using a point;\n",
    "#### 2. Data in two dimension - Bidimensional data points can be represented using a plane, and classified using a line;\n",
    "\n",
    "#### Data in N-Dimension - N-dimensional data can be represented in a hypercube, and classified using a hyperplane;  ------------  SVM;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### -----------------------------------------------------------------------------------------------\n",
    "### Build ML-based Sentiment Analysis System:\n",
    "#### Importance of feature Extraction:\n",
    "#### ---------------------------------------------------\n",
    "#### Smart feature selection is key to making ML-based approaches work.\n",
    "#### Feature Vector: Word Tuple - Presence or absence of a word in a review works fine for Naive Bayes Classifier;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#                      Word Tuples               \n",
    "##                amazing   |   worst movie ever   | two thumbs up  \n",
    "# amazing           1       |           0          |      0\n",
    "# worst             0       |           1          |      0\n",
    "# movie             0       |           1          |      0\n",
    "# ever              0       |           1          |      0\n",
    "# two               0       |           0          |      1\n",
    "# thumbs            0       |           0          |      1\n",
    "# up                0       |           0          |      1 \n",
    "# part              0       |           0          |      0\n",
    "# was               0       |           0          |      0\n",
    "#  bad              0       |           0          |      0\n",
    "#  3                0       |           0          |      0\n",
    "#  the              0       |           0          |      0\n",
    "# there             0       |           0          |      0\n",
    "#  with             0       |           0          |      0\n",
    "#  greats           0       |           0          |      0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#                      Word Tuples   \n",
    "# Reviews                                              |Feature Vector\n",
    "# Amazing!                                             |(1,0,0,0,0,0,0,...)\n",
    "# Worst movie ever                                     |(0,1,1,1,0,0,0,...)\n",
    "# Two thumbs up                                        |(0,0,0,0,1,1,1,...)\n",
    "# Part 2 was bad, 3 worst                              |      ...\n",
    "# Up there with the greats                             |      ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now compare, measure distance using simple geometry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection for Text Documents:\n",
    "#### i. Word tuples: Works fine for Naive Bayes classifiers;\n",
    "#### ii. Term Frequency(tf): Captures frequency information; useful in SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### -----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing an ML-based approach using Naive Bayes\n",
    "#### Step 1: - Split the corpus - test and training dataset;\n",
    "#### Step 2: - Define vocabulary - Set of all words - use training data only;\n",
    "#### Step 3: - Extract Features - Create word tuples - use vocabulary;\n",
    "#### Step 4: - Train Classifier - Done by nltk - Use training data only;\n",
    "#### Step 5: - Classify Test Data - Done by nltk - use test data;\n",
    "#### Step 6: - Measure Accuracy - On test data - Compare to VADER;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: - Split the corpus - test and training dataset\n",
    "#### Positive reviews 0 - 5330; Negative reviews 0 - 5330;\n",
    "#### Split into training (0-2500); test (2501-5330);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Read in the Reviews\n",
    "negativeReviewsFileName = \"/Users/AMI_1234/Documents/Computer_programs/ML/python_ml/nlp_movie_review/rt-polaritydata/rt-polarity.neg\"\n",
    "\n",
    "with open(negativeReviewsFileName, 'r') as f:\n",
    "    negativeReviews = f.readlines()\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Read in the Reviews\n",
    "positiveReviewsFileName = \"/Users/AMI_1234/Documents/Computer_programs/ML/python_ml/nlp_movie_review/rt-polaritydata/rt-polarity.pos\"\n",
    "\n",
    "with open(positiveReviewsFileName, 'r') as f:\n",
    "    positiveReviews = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testTrainingSplitIndex = 2500\n",
    "\n",
    "testNegativeReviews = negativeReviews[testTrainingSplitIndex+1:]\n",
    "testPositiveReviews = positiveReviews[testTrainingSplitIndex+1:]\n",
    "\n",
    "trainingNegativeReviews = negativeReviews[:testTrainingSplitIndex]\n",
    "trainingPositiveReviews = positiveReviews[:testTrainingSplitIndex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: - Define vocabulary - Set of all words - use training data only:\n",
    "#### Create a set of all words in the training data.\n",
    "#### A list in which each word in the training data occurs exactly once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positiveWordList = [word for line in trainingPositiveReviews for word in line.split()]\n",
    "negativeWordList = [word for line in trainingNegativeReviews for word in line.split()]\n",
    "allWordList = [item for sublist in [positiveWordList, negativeWordList] for item in sublist]\n",
    "vocabulary = list(set(allWordList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: - Extract Features - Create word tuples - use vocabulary:\n",
    "#### Express each review as a tuple of 1,0 elements. 1 where the location of the word is indicated.\n",
    "#### Feature extraction - a function that takes in a review and returns a feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(review):\n",
    "    review_words=set(review)\n",
    "    features={}\n",
    "    for word in vocabulary:\n",
    "        features[word]=(word in review_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert list of elements into tuple:\n",
    "#### A list of tuples: first element in each tuple is the review, second element is the label;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negTaggedTrainingReviewList = [{'review':oneReview.split(),'label':'negative'} for oneReview in trainingNegativeReviews]\n",
    "posTaggedTrainingReviewList = [{'review':oneReview.split(),'label':'positive'} for oneReview in trainingPositiveReviews]\n",
    "fullTaggedTrainingData = [item for sublist in [negTaggedTrainingReviewList, posTaggedTrainingReviewList] for item in sublist]\n",
    "trainingData = [(review['review'], review['label']) for review in fullTaggedTrainingData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingFeatures = nltk.classify.apply_features(extract_features, trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: - Train Classifier - Done by nltk - Use training data only\n",
    "#### Input feature vector and labels, output is a ready-to-use classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainedNBClassifier = nltk.NaiveBayesClassifier.train(trainingFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: - Classify Test Data - Done by nltk - use test data\n",
    "#### Trained classifier on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naiveBayesSentimentCalculator(review):\n",
    "    problemInstance = review.split()\n",
    "    problemFeatures = extract_features(problemInstance)\n",
    "    return trainedNBClassifier.classify(problemFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: - Measure Accuracy - On test data - Compare to VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTestReviewSentiments(naiveBayesSentimentCalculator):\n",
    "    testNegativeResults = [naiveBayesSentimentCalculator(review) for review in testNegativeReviews]\n",
    "    testPositiveResults = [naiveBayesSentimentCalculator(review) for review in testPositiveReviews]\n",
    "    labelToNum = {'positive':1, 'negative':-1}\n",
    "    numericNegResults = [labelToNum[x] for x in testNegativeResults]\n",
    "    numericPosResults = [labelToNum[x] for x in testPositiveResults]\n",
    "    return {'results-on-positive':numericPosResults,'results-on-negative':numericNegResults}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------------------------------  DEMO ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "## Read in the Reviews\n",
    "positiveReviewsFileName = \"/Users/AMI_1234/Documents/Computer_programs/ML/python_ml/nlp_movie_review/rt-polaritydata/rt-polarity.pos\"\n",
    "\n",
    "with open(positiveReviewsFileName, 'r') as f:\n",
    "    positiveReviews = f.readlines()\n",
    "\n",
    "## Read in the Reviews\n",
    "negativeReviewsFileName = \"/Users/AMI_1234/Documents/Computer_programs/ML/python_ml/nlp_movie_review/rt-polaritydata/rt-polarity.neg\"\n",
    "\n",
    "with open(negativeReviewsFileName, 'r') as f:\n",
    "    negativeReviews = f.readlines()\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testTrainingSplitIndex = 2500\n",
    "\n",
    "testNegativeReviews = negativeReviews[testTrainingSplitIndex+1:]\n",
    "testPositiveReviews = positiveReviews[testTrainingSplitIndex+1:]\n",
    "\n",
    "trainingNegativeReviews = negativeReviews[:testTrainingSplitIndex]\n",
    "trainingPositiveReviews = positiveReviews[:testTrainingSplitIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getVocabulary():\n",
    "    positiveWordList = [word for line in trainingPositiveReviews for word in line.split()]\n",
    "    negativeWordList = [word for line in trainingNegativeReviews for word in line.split()]\n",
    "    allWordList = [item for sublist in [positiveWordList, negativeWordList] for item in sublist]\n",
    "    allWordSet = list(set(allWordList))\n",
    "    vocabulary = allWordSet\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = getVocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'engineering'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14102"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrainingData():\n",
    "    negTaggedTrainingReviewList = [{'review':oneReview.split(),'label':'negative'} for oneReview in trainingNegativeReviews]\n",
    "    posTaggedTrainingReviewList = [{'review':oneReview.split(),'label':'positive'} for oneReview in trainingPositiveReviews]\n",
    "    fullTaggedTrainingData = [item for sublist in [negTaggedTrainingReviewList, posTaggedTrainingReviewList] for item in sublist]\n",
    "    trainingData = [(review['review'], review['label']) for review in fullTaggedTrainingData]\n",
    "    return trainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingData = getTrainingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['simplistic', ',', 'silly', 'and', 'tedious', '.'], 'negative')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData[0] # test and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(review):\n",
    "    review_words=set(review)\n",
    "    features={}\n",
    "    for word in vocabulary:\n",
    "        features[word]=(word in review_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrainedNaiveBayesClassifier(extract_features, trainingData):\n",
    "    trainingFeatures = nltk.classify.apply_features(extract_features, trainingData)\n",
    "    trainedNBClassifier = nltk.NaiveBayesClassifier.train(trainingFeatures)\n",
    "    return trainedNBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainedNBClassifier = getTrainedNaiveBayesClassifier(extract_features, trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naiveBayesSentimentCalculator(review):\n",
    "    problemInstance = review.split()\n",
    "    problemFeatures = extract_features(problemInstance)\n",
    "    return trainedNBClassifier.classify(problemFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naiveBayesSentimentCalculator(\"What an awesome movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naiveBayesSentimentCalculator(\"What a terrible movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTestReviewSentiments(naiveBayesSentimentCalculator):\n",
    "    testNegativeResults = [naiveBayesSentimentCalculator(review) for review in testNegativeReviews]\n",
    "    testPositiveResults = [naiveBayesSentimentCalculator(review) for review in testPositiveReviews]\n",
    "    labelToNum = {'positive':1, 'negative':-1}\n",
    "    numericNegResults = [labelToNum[x] for x in testNegativeResults]\n",
    "    numericPosResults = [labelToNum[x] for x in testPositiveResults]\n",
    "    return {'results-on-positive':numericPosResults,'results-on-negative':numericNegResults}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviewResult = getTestReviewSentiments(naiveBayesSentimentCalculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runDiagnostics(reviewResult):\n",
    "    positiveReviewsResult = reviewResult['results-on-positive']\n",
    "    negativeReviewsResult = reviewResult['results-on-negative']\n",
    "    pctTruePositive = float(sum(x > 0 for x in positiveReviewsResult)) / len(positiveReviewsResult)\n",
    "    pctTrueNegative = float(sum(x < 0 for x in negativeReviewsResult)) / len(negativeReviewsResult)\n",
    "    totalAccurate = float(sum(x > 0 for x in positiveReviewsResult)) + float(sum(x < 0 for x in negativeReviewsResult))\n",
    "    total = len(positiveReviewsResult) + len(negativeReviewsResult)\n",
    "    print(\"Accuracy on positive reviews = \" + \"%.2f\" % (pctTruePositive*100) + \"%\")\n",
    "    print(\"Accuracy on negative reviews = \" + \"%.2f\" % (pctTrueNegative*100) + \"%\")\n",
    "    print(\"Overall accuracy = \" + \"%.2f\" % (totalAccurate*100/total) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on positive reviews = 73.39%\n",
      "Accuracy on negative reviews = 77.07%\n",
      "Overall accuracy = 75.23%\n"
     ]
    }
   ],
   "source": [
    "runDiagnostics(getTestReviewSentiments(naiveBayesSentimentCalculator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
